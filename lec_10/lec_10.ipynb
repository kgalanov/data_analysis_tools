{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:29:20.781249Z",
     "start_time": "2024-04-03T10:29:20.776247Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kgalanov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kgalanov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kgalanov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:29:20.791247Z",
     "start_time": "2024-04-03T10:29:20.785255Z"
    }
   },
   "id": "34a96dcf64a2c1ff",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['спасибо',\n 'скачали',\n 'книгу',\n 'бесплатной',\n 'электронной',\n 'библиотеке',\n 'royallib.ru',\n 'http',\n '//royallib.ru',\n 'книги',\n 'автора',\n 'http',\n '//royallib.ru/author/tolstoy_lev.html',\n 'эта',\n 'книга',\n 'других',\n 'форматах',\n 'http',\n '//royallib.ru/book/tolstoy_lev/voyna_i_mir_kniga_1.html',\n 'приятного',\n 'чтения',\n 'первый',\n 'часть',\n 'первая',\n 'i',\n '–',\n 'eh',\n 'bien',\n 'mon',\n 'prince',\n 'g',\n '234',\n 'ne',\n 'et',\n 'lucques',\n 'ne',\n 'sont',\n 'plus',\n 'que',\n 'de',\n 'apanage',\n 'de',\n 'поместья',\n 'de',\n 'la',\n 'famille',\n 'buonaparte',\n 'non',\n 'je',\n 'vous',\n 'pr',\n '233',\n 'viens',\n 'que',\n 'si',\n 'vous',\n 'ne',\n 'me',\n 'dites',\n 'pa',\n 'que',\n 'nous',\n 'avon',\n 'la',\n 'guerre',\n 'si',\n 'vous',\n 'vous',\n 'permettez',\n 'encore',\n 'de',\n 'pallier',\n 'toutes',\n 'le',\n 'infamy',\n 'toutes',\n 'le',\n 'atrocit',\n '233',\n 's',\n 'de',\n 'cet',\n 'antichrist',\n 'ma',\n 'parole',\n 'j',\n '’',\n 'y',\n 'crois',\n '–',\n 'je',\n 'ne',\n 'vous',\n 'connais',\n 'plus',\n 'vous',\n 'n',\n '’',\n '234',\n 'te',\n 'plus',\n 'mon',\n 'ami',\n 'vous',\n 'n',\n '’',\n '234',\n 'te',\n 'plus',\n 'верный',\n 'раб',\n 'comme',\n 'vous',\n 'dites',\n '1',\n 'князь',\n 'генуя',\n 'лукка',\n '–',\n 'поместья',\n 'фамилии',\n 'бонапарте',\n 'вперед',\n 'говорю',\n 'скажете',\n 'война',\n 'позволите',\n 'защищать',\n 'гадости',\n 'ужасы',\n 'антихриста',\n 'право',\n 'верю',\n 'антихрист',\n '–',\n 'знаю',\n 'друг',\n 'верный',\n 'раб',\n 'говорите',\n 'франц.',\n 'дальнейшем',\n 'переводы',\n 'французского',\n 'оговариваются',\n 'далее',\n 'переводы',\n 'кроме',\n 'специально',\n 'оговоренных',\n 'принадлежат',\n 'л.',\n 'н.',\n 'толстому',\n '–',\n 'ред',\n 'здравствуйте',\n 'здравствуйте',\n 'je',\n 'vois',\n 'que',\n 'je',\n 'vous',\n 'fais',\n 'peur',\n '2',\n 'вижу',\n 'пугаю',\n 'садитесь',\n 'рассказывайте',\n 'говорила',\n 'июле',\n '1805',\n 'года',\n 'известная',\n 'анна',\n 'павловна',\n 'шерер',\n 'фрейлина',\n 'приближенная',\n 'императрицы',\n 'марии',\n 'феодоровны',\n 'встречая',\n 'важного',\n 'чиновного',\n 'князя',\n 'василия',\n 'первого',\n 'приехавшего',\n 'вечер',\n 'анна',\n 'павловна',\n 'кашляла',\n 'несколько',\n 'дней',\n 'грипп',\n 'говорила',\n 'грипп',\n 'новое',\n 'слово',\n 'употреблявшееся',\n 'редкими',\n 'записочках',\n 'разосланных',\n 'утром',\n 'красным',\n 'лакеем',\n 'написано',\n 'различия',\n '«',\n 'si',\n 'vous',\n 'n',\n '’',\n 'avez',\n 'rien',\n 'de',\n 'mieux',\n 'faire',\n 'monsieur',\n 'le',\n 'comte',\n 'mon',\n 'prince',\n 'et',\n 'si',\n 'la',\n 'perspective',\n 'de',\n 'passer',\n 'la',\n 'soir',\n '233',\n 'e',\n 'chez',\n 'une',\n 'pauvre',\n 'malade',\n 'ne',\n 'vous',\n 'effraye',\n 'pa',\n 'trop',\n 'je',\n 'serai',\n 'charm',\n '233',\n 'e',\n 'de',\n 'vous',\n 'voir',\n 'chez',\n 'moi',\n 'entre',\n '7',\n 'et',\n '10',\n 'heures',\n 'annette',\n 'scherer',\n '»',\n '3',\n 'граф',\n 'князь',\n 'виду',\n 'лучшего',\n 'перспектива',\n 'вечера',\n 'бедной',\n 'больной',\n 'слишком',\n 'пугает',\n 'буду',\n 'очень',\n 'рада',\n 'видеть',\n 'нынче',\n 'семью',\n 'десятью',\n 'часами',\n 'анна',\n 'шерер',\n '–',\n 'dieu',\n 'quelle',\n 'virulente',\n 'sortie',\n '4',\n 'господи',\n 'какое',\n 'горячее',\n 'нападение',\n '–',\n 'отвечал',\n 'нисколько',\n 'смутясь',\n 'такою',\n 'встречей',\n 'вошедший',\n 'князь',\n 'придворном',\n 'шитом',\n 'мундире',\n 'чулках',\n 'башмаках',\n 'звездах',\n 'светлым',\n 'выражением',\n 'плоского',\n 'лица',\n 'говорил',\n 'изысканном',\n 'французском',\n 'языке',\n 'котором',\n 'говорили',\n 'думали',\n 'наши',\n 'деды',\n 'теми',\n 'тихими',\n 'покровительственными',\n 'интонациями',\n 'которые',\n 'свойственны',\n 'состаревшемуся',\n 'свете',\n 'дворе',\n 'значительному',\n 'человеку',\n 'подошел',\n 'анне',\n 'павловне',\n 'поцеловал',\n 'руку',\n 'подставив',\n 'надушенную',\n 'сияющую',\n 'лысину',\n 'покойно',\n 'уселся',\n 'диване',\n '–',\n 'avant',\n 'tout',\n 'dites-moi',\n 'comment',\n 'vous',\n 'allez',\n 'ch',\n '232',\n 'e',\n 'amie',\n '5',\n 'прежде',\n 'скажите',\n 'ваше',\n 'здоровье',\n 'милый',\n 'друг',\n 'успокойте',\n '–',\n 'сказал',\n 'изменяя',\n 'голоса',\n 'тоном',\n 'котором',\n 'из-за',\n 'приличия',\n 'участия',\n 'просвечивало',\n 'равнодушие',\n 'насмешка',\n '–',\n 'здоровой…',\n 'нравственно',\n 'страдаешь',\n 'имея',\n 'чувство',\n 'оставаться',\n 'спокойною',\n 'наше',\n 'время',\n '–',\n 'сказала',\n 'анна',\n 'павловна',\n '–',\n 'весь',\n 'вечер',\n 'надеюсь',\n '–',\n 'праздник',\n 'английского',\n 'посланника',\n 'нынче',\n 'середа',\n 'показаться',\n '–',\n 'сказал',\n 'князь',\n '–',\n 'дочь',\n 'заедет',\n 'мной',\n 'повезет',\n '–',\n 'думала',\n 'нынешний',\n 'праздник',\n 'отменен',\n 'je',\n 'vous',\n 'avoue',\n 'que',\n 'toutes',\n 'ce',\n 'f',\n '234',\n 'te',\n 'et',\n 'ton',\n 'ce',\n 'feux',\n 'd',\n '’',\n 'artifice',\n 'commencent',\n 'devenir',\n 'insipides',\n '6',\n 'признаюсь',\n 'праздники',\n 'фейерверки',\n 'становятся',\n 'несносны',\n '–',\n 'ежели',\n 'знали',\n 'хотите',\n 'праздник',\n 'отменили',\n '–',\n 'сказал',\n 'князь',\n 'привычке',\n 'заведенные',\n 'часы',\n 'говоря',\n 'вещи',\n 'которым',\n 'хотел',\n 'верили',\n '–',\n 'ne',\n 'me',\n 'tourmentez',\n 'pa',\n 'eh',\n 'bien',\n 'qu',\n '’',\n 'a-t-on',\n 'd',\n '233',\n 'cid',\n '233',\n 'par',\n 'rapport',\n 'la',\n 'd',\n '233',\n 'p',\n '234',\n 'che',\n 'de',\n 'novosilzoff',\n 'vous',\n 'savez',\n 'tout',\n '7',\n 'мучьте',\n 'решили',\n 'случаю',\n 'депеши',\n 'новосильцева',\n 'всё',\n 'знаете',\n '–',\n 'сказать',\n '–',\n 'сказал',\n 'князь',\n 'холодным',\n 'скучающим',\n 'тоном',\n '–',\n 'qu',\n '’',\n 'a-t-on',\n 'd',\n '233',\n 'cid',\n '233',\n 'on',\n 'a',\n 'd',\n '233',\n 'cid',\n '233',\n 'que',\n 'buonaparte',\n 'a',\n 'br',\n '251',\n 'l',\n '233',\n 's',\n 'vaisseaux',\n 'et',\n 'je',\n 'crois',\n 'que',\n 'nous',\n 'somme',\n 'en',\n 'train',\n 'de',\n 'br',\n '251',\n 'ler',\n 'le',\n 'n',\n '244',\n 'tres',\n '8',\n 'решили',\n 'решили',\n 'бонапарте',\n 'сжег',\n 'свои',\n 'корабли',\n 'кажется',\n 'готовы',\n 'сжечь',\n 'наши',\n 'князь',\n 'василий',\n 'говорил',\n 'лениво',\n 'актер',\n 'говорит',\n 'роль',\n 'старой',\n 'пиесы',\n 'анна',\n 'павловна',\n 'шерер',\n 'напротив',\n 'несмотря',\n 'свои',\n 'сорок',\n 'лет',\n 'преисполнена',\n 'оживления',\n 'порывов',\n 'энтузиасткой',\n 'сделалось',\n 'общественным',\n 'положением',\n 'хотелось',\n 'обмануть',\n 'ожиданий',\n 'людей',\n 'знавших',\n 'делалась',\n 'энтузиасткой',\n 'сдержанная',\n 'улыбка',\n 'игравшая',\n 'постоянно',\n 'лице',\n 'анны',\n 'павловны',\n 'хотя',\n 'шла',\n 'отжившим',\n 'чертам',\n 'выражала',\n 'избалованных',\n 'детей',\n 'постоянное',\n 'сознание',\n 'своего',\n 'милого',\n 'недостатка',\n 'которого',\n 'хочет',\n 'находит',\n 'нужным',\n 'исправляться',\n 'середине',\n 'разговора',\n 'политические',\n 'действия',\n 'анна',\n 'павловна',\n 'разгорячилась',\n '–',\n 'ах',\n 'говорите',\n 'австрию',\n 'понимаю',\n 'австрия',\n 'хотела',\n 'хочет',\n 'войны',\n 'предает',\n 'россия',\n 'одна',\n 'должна',\n 'спасительницей',\n 'европы',\n 'наш',\n 'благодетель',\n 'знает',\n 'свое',\n 'высокое',\n 'призвание',\n 'верен',\n 'одно',\n 'верю',\n 'нашему',\n 'доброму',\n 'чудному',\n 'государю',\n 'предстоит',\n 'величайшая',\n 'роль',\n 'мире',\n 'добродетелен',\n 'хорош',\n 'бог',\n 'оставит',\n 'исполнит',\n 'свое',\n 'призвание',\n 'задавить',\n 'гидру',\n 'революции',\n 'которая',\n 'ужаснее',\n 'лице',\n 'убийцы',\n 'злодея',\n 'одни',\n 'должны',\n 'искупить',\n 'кровь',\n 'праведника',\n 'кого',\n 'нам',\n 'надеяться',\n 'спрашиваю',\n '..',\n 'англия',\n 'своим',\n 'коммерческим',\n 'духом',\n 'поймет',\n 'понять',\n 'высоту',\n 'души',\n 'императора',\n 'александра',\n 'отказалась',\n 'очистить',\n 'мальту',\n 'хочет',\n 'видеть',\n 'ищет',\n 'заднюю',\n 'мысль',\n 'наших',\n 'действий',\n 'сказали',\n 'новосильцеву',\n 'поняли',\n 'могут',\n 'понять',\n 'самоотвержения',\n 'нашего',\n 'императора',\n 'который',\n 'хочет',\n 'хочет',\n 'блага',\n 'мира',\n 'обещали',\n 'обещали',\n 'пруссия',\n 'объявила',\n 'бонапарте',\n 'непобедим',\n 'вся',\n 'европа',\n 'против',\n 'него…',\n 'верю',\n 'одном',\n 'слове',\n 'гарденбергу',\n 'гаугвицу',\n 'cette',\n 'fameuse',\n 'neutralit',\n '233',\n 'prussienne',\n 'ce',\n 'n',\n '’',\n 'est',\n 'qu',\n '’',\n 'un',\n 'pi',\n '232',\n 'e.',\n '9',\n 'пресловутый',\n 'нейтралитет',\n 'пруссии',\n '–',\n 'западня',\n 'верю',\n 'одного',\n 'бога',\n 'высокую',\n 'судьбу',\n 'нашего',\n 'милого',\n 'императора',\n 'спасет',\n 'европу',\n '..',\n '–',\n 'остановилась',\n 'улыбкой',\n 'насмешки',\n 'своею',\n 'горячностью',\n '–',\n 'думаю',\n '–',\n 'сказал',\n 'князь',\n 'улыбаясь',\n '–',\n 'ежели',\n 'послали',\n 'вместо',\n 'нашего',\n 'милого',\n 'винценгероде',\n 'взяли',\n 'приступом',\n 'согласие',\n 'прусского',\n 'короля',\n 'красноречивы',\n 'дадите',\n 'чаю',\n '–',\n 'a',\n 'propos',\n '–',\n 'прибавила',\n 'успокоиваясь',\n '–',\n 'нынче',\n 'очень',\n 'интересные',\n 'человека',\n 'le',\n 'vicomte',\n 'de',\n 'mortemart',\n 'il',\n 'est',\n 'alli',\n '233',\n 'aux',\n 'montmorency',\n 'par',\n 'le',\n 'rohans',\n '10',\n 'кстати',\n '–',\n 'виконт',\n 'мортемар',\n 'родстве',\n 'монморанси',\n 'чрез',\n 'роганов',\n 'одна',\n 'лучших',\n 'фамилий',\n 'франции',\n 'это',\n 'хороших',\n 'эмигрантов',\n 'настоящих',\n 'l',\n '’',\n 'abb',\n '233',\n 'morio',\n '11',\n 'аббат',\n 'морио',\n 'знаете',\n 'глубокий',\n 'ум',\n 'принят',\n 'государем',\n 'знаете',\n '–',\n 'очень',\n 'рад',\n 'буду',\n '–',\n 'сказал',\n 'князь',\n '–',\n 'скажите',\n '–',\n 'прибавил',\n 'вспомнив',\n 'что-то',\n 'особенно-небрежно',\n 'спрашивал',\n 'главной',\n 'целью',\n 'посещения',\n '–',\n 'правда',\n 'i',\n '’',\n 'imp',\n '233',\n 'ratrice-mer',\n '232',\n '12',\n 'вдовствующая',\n 'императрица',\n 'желает',\n 'назначения',\n 'барона',\n 'функе',\n 'первым',\n 'секретарем',\n 'вену',\n 'c',\n '’',\n 'est',\n 'un',\n 'pauvre',\n 'sire',\n 'ce',\n 'baron',\n 'qu',\n '’',\n 'il',\n 'para',\n '238',\n 't.',\n '13',\n 'барон',\n 'ничтожное',\n 'существо',\n 'кажется',\n '–',\n 'князь',\n 'василий',\n 'желал',\n 'определить',\n 'сына',\n 'это',\n 'место',\n 'которое',\n 'императрицу',\n 'марию',\n 'феодоровну',\n 'старались',\n 'доставить',\n 'барону',\n 'анна',\n 'павловна',\n 'закрыла',\n 'глаза',\n 'знак',\n 'могут',\n 'судить',\n 'угодно',\n 'нравится',\n 'императрице',\n '–',\n 'monsieur',\n 'le',\n 'baron',\n 'de',\n 'funke',\n 'a',\n '233',\n 't',\n '233',\n 'recommand',\n '233',\n 'l',\n '’',\n 'imp',\n '233',\n 'ratrice-m',\n '232',\n 'e',\n 'par',\n 'sa',\n 'soeur',\n '14',\n 'барон',\n 'функе',\n 'рекомендован',\n 'императрице-матери',\n 'сестрою',\n '–',\n 'сказала',\n 'грустным',\n 'сухим',\n 'тоном',\n 'время',\n 'анна',\n 'павловна',\n 'назвала',\n 'императрицу',\n 'лицо',\n 'представило',\n 'глубокое',\n 'искреннее',\n 'выражение',\n 'преданности',\n 'уважения',\n 'соединенное',\n 'грустью',\n 'бывало',\n 'каждый',\n 'разговоре',\n 'упоминала',\n 'своей',\n 'высокой',\n 'покровительнице',\n 'сказала',\n 'величество',\n 'изволила',\n 'оказать',\n 'барону',\n 'функе',\n 'beaucoup',\n 'd',\n '’',\n 'estime',\n '15',\n 'уважения',\n 'взгляд',\n 'подернулся',\n 'грустью',\n 'князь',\n 'равнодушно',\n 'замолк',\n 'анна',\n 'павловна',\n 'свойственною',\n 'придворною',\n 'женскою',\n 'ловкостью',\n 'быстротою',\n 'такта',\n 'захотела',\n 'щелкануть',\n 'князя',\n 'дерзнул',\n 'отозваться',\n 'лице',\n 'рекомендованном',\n 'императрице',\n 'время',\n 'утешить',\n '–',\n 'mais',\n ...]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = open('data.txt', 'r').read()\n",
    "\n",
    "text_data = text_data.lower()\n",
    "\n",
    "tokens = word_tokenize(text_data)\n",
    "\n",
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:29:22.714857Z",
     "start_time": "2024-04-03T10:29:20.792247Z"
    }
   },
   "id": "9a6b55d1643110c9",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted categories for new data: ['alt.atheism' 'comp.graphics']\n",
      "Most relevant categories based on cluster centers:\n",
      "Cluster 0: comp.graphics\n",
      "Cluster 1: alt.atheism\n",
      "Cluster 2: sci.med\n",
      "Cluster 3: soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "data = fetch_20newsgroups(categories=categories)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data.data)\n",
    "\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X, data.target)\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(categories))\n",
    "kmeans.fit(X)\n",
    "\n",
    "new_data = [\"Atheism is a non-prophet organization\", \"OpenGL on the GPU is fast\"]\n",
    "X_new = vectorizer.transform(new_data)\n",
    "predicted = classifier.predict(X_new)\n",
    "\n",
    "print(f\"Predicted categories for new data: {np.array(data.target_names)[predicted]}\")\n",
    "\n",
    "cluster_centers_indices = np.argsort(kmeans.cluster_centers_.sum(axis=1))\n",
    "print(\"Most relevant categories based on cluster centers:\")\n",
    "for i, center_idx in enumerate(cluster_centers_indices):\n",
    "    print(f\"Cluster {i}: {data.target_names[center_idx]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:29:28.301214Z",
     "start_time": "2024-04-03T10:29:22.716199Z"
    }
   },
   "id": "b15a6473c151b0c0",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'learning': [-7.1909428e-03  4.2328904e-03  2.1633946e-03  7.4407146e-03\n",
      " -4.8892652e-03 -4.5643463e-03 -6.0981740e-03  3.2993674e-03\n",
      " -4.4994629e-03  8.5228849e-03 -4.2888271e-03 -9.1054197e-03\n",
      " -4.8163556e-03  6.4164903e-03 -6.3713240e-03 -5.2615367e-03\n",
      " -7.3044109e-03  6.0222615e-03  3.3575939e-03  2.8483903e-03\n",
      " -3.1385506e-03  6.0308911e-03 -6.1527453e-03 -1.9801008e-03\n",
      " -5.9830821e-03 -9.9568011e-04 -2.0209861e-03  8.4859459e-03\n",
      "  7.8001023e-05 -8.5753258e-03 -5.4290984e-03 -6.8759858e-03\n",
      "  2.6923812e-03  9.4566476e-03 -5.8159959e-03  8.2650259e-03\n",
      "  8.5320519e-03 -7.0626391e-03 -8.8832127e-03  9.4691841e-03\n",
      "  8.3743641e-03 -4.6908916e-03 -6.7260410e-03  7.8421365e-03\n",
      "  3.7633455e-03  8.0955038e-03 -7.5715459e-03 -9.5250849e-03\n",
      "  1.5774060e-03 -9.8057678e-03 -4.8858845e-03 -3.4601032e-03\n",
      "  9.6209226e-03  8.6235693e-03 -2.8356076e-03  5.8268728e-03\n",
      "  8.2370946e-03 -2.2629809e-03  9.5285419e-03  7.1602152e-03\n",
      "  2.0415008e-03 -3.8487636e-03 -5.0817500e-03 -3.0516528e-03\n",
      "  7.8878645e-03 -6.1904346e-03 -2.9150224e-03  9.1910223e-03\n",
      "  3.4566557e-03  6.0726120e-03 -8.0328165e-03 -7.5150491e-04\n",
      "  5.5224476e-03 -4.7144685e-03  7.4784933e-03  9.3195913e-03\n",
      " -4.0936828e-04 -2.0636010e-03 -5.9335830e-04 -5.7858895e-03\n",
      " -8.3862813e-03 -1.5068734e-03 -2.5571836e-03  4.3824338e-03\n",
      " -6.8675173e-03  5.4136957e-03 -6.7450856e-03 -7.8202896e-03\n",
      "  8.4717115e-03  8.9186141e-03 -3.4812402e-03  3.4914147e-03\n",
      " -5.7957349e-03 -8.7500857e-03 -5.5155717e-03  6.7487289e-03\n",
      "  6.4177597e-03  9.4380733e-03  7.0552849e-03  6.7549525e-03]\n",
      "Document vector for document 0: [-0.00555126 -0.0060502  -0.00991733  0.00884265  0.00365807  0.00011367\n",
      " -0.00991601 -0.00507741 -0.00984765  0.00198974  0.00282432  0.00450881\n",
      " -0.0043641  -0.00326847 -0.00291137 -0.00884863  0.00216039  0.00926991\n",
      " -0.00965294 -0.00357022 -0.00379381  0.00273019 -0.00574842  0.00279178\n",
      "  0.00576031 -0.00808351 -0.00868456 -0.01005656  0.00502199 -0.00931912\n",
      "  0.00604482  0.00673334 -0.00650863 -0.00467939 -0.00136924  0.00180595\n",
      " -0.00139566 -0.0086348  -0.0037852   0.00172708 -0.00186434 -0.00734185\n",
      "  0.00426346 -0.00871219  0.00265862 -0.00471732  0.00061886 -0.00196797\n",
      "  0.00540756 -0.00827966 -0.00217811 -0.00012118 -0.00679388 -0.00671292\n",
      " -0.00208047  0.0091338  -0.00111166  0.00373013 -0.00583561  0.00898896\n",
      "  0.00296107  0.00950177  0.0047319  -0.00422384  0.00225396 -0.00440655\n",
      "  0.00581552  0.00189873 -0.0024229  -0.00591764 -0.00825867 -0.00078938\n",
      " -0.00899206 -0.00925592 -0.00790351  0.00219295 -0.00664702 -0.00797582\n",
      "  0.00208445  0.00205713  0.0083325   0.00480441 -0.00951836 -0.00037932\n",
      "  0.00779415  0.0029211   0.00271732 -0.00505226  0.00672107  0.00179192\n",
      " -0.0078199   0.00705652 -0.00991805 -0.00821256 -0.00479785  0.01019352\n",
      "  0.00322903 -0.00205301  0.00913279  0.0024349 ]\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is the study of computer algorithms that improve automatically through experience.\",\n",
    "    \"Data science is an interdisciplinary field focused on extracting knowledge from data sets.\",\n",
    "    \"Python is a widely used high-level programming language for general-purpose programming.\",\n",
    "]\n",
    "\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "word_vector = word2vec_model.wv[\"learning\"]\n",
    "print(\"Word vector for 'learning':\", word_vector)\n",
    "\n",
    "tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized_documents)]\n",
    "doc2vec_model = Doc2Vec(tagged_documents, vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "\n",
    "doc_vector = doc2vec_model.dv[0]\n",
    "print(\"Document vector for document 0:\", doc_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:35:59.900535Z",
     "start_time": "2024-04-03T10:35:59.847004Z"
    }
   },
   "id": "978c1e55d32f762d",
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
